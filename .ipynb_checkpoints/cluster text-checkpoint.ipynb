{
 "metadata": {
  "name": "",
  "signature": "sha256:2986addec3862bab2e953c05af2342df1fb0fa8f47ab94418d1455bd08a14648"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from BeautifulSoup import BeautifulSoup\n",
      "import re\n",
      "import nltk\n",
      "from nltk import word_tokenize\n",
      "from __future__ import division\n",
      "from nltk.corpus import stopwords\n",
      "import string\n",
      "from nltk.stem import SnowballStemmer\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "posts = open('raw_forum_posts.dat', 'rw').read()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "soup = BeautifulSoup(posts)\n",
      "postTxt = soup.findAll('text')  #all posts <text> \n",
      "postDocs = [x.text for x in postTxt]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "emptyOne = postDocs.pop(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tokenizePosts(postDocs):\n",
      "    tokenizedDocs = []\n",
      "    #stopwords\n",
      "    stopset = set(stopwords.words('english'))\n",
      "    stopset.update(['lt','p','/p','br'])\n",
      "    tokenizedDocs = []\n",
      "    \n",
      "    for doc in postDocs:\n",
      "        words = word_tokenize(doc)\n",
      "        filtered_words = [w for w in words if not w in stopset]\n",
      "        filtered_words = [w for w in filtered_words if not w in string.punctuation]\n",
      "        tokenizedDocs.append(filtered_words)\n",
      "    return tokenizedDocs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 183
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokenizedDocs = tokenizePosts(postDocs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 184
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def stem_tokens(tokens):\n",
      "    stemmed = []\n",
      "    stemmer = SnowballStemmer('english')\n",
      "    for item in tokens:\n",
      "        stemmed.append(str(stemmer.stem(item)))\n",
      "    return stemmed\n",
      "\n",
      "def StemTokens(tokenizedDocs):\n",
      "    stemmedDocs = []\n",
      "    for doc in tokenizedDocs:\n",
      "        stemmedDocs.append(stem_tokens(doc))\n",
      "    return stemmedDocs\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 185
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stemmedDocs = StemTokens(tokenizedDocs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 186
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 187
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf = TfidfVectorizer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "doc0 = tfidf.fit_transform(stemmedDocs[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "doc0.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 190,
       "text": [
        "(126, 86)"
       ]
      }
     ],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(stemmedDocs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 191,
       "text": [
        "25"
       ]
      }
     ],
     "prompt_number": 191
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print stemmedDocs[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['at', \"'s\", 'fundament', 'core', 'i', 'believ', 'data', 'scienc', 'ultim', 'way', 'allow', 'peopl', 'busi', 'compound', 'work', 'observ', 'essenti', \"'s\", 'data', '--', 'record', 'observ', 'gain', 'much', 'understand', 'context', 'problem', 'possibl', 'use', 'inform', 'generat', 'make', 'deeper', 'insight', 'greater', 'decis', 'ultim', 'shift', 'paradigm', 'propel', 'human', 'forward', 'as', 'mention', 'lectur', 'ultim', 'data', 'use', 'solv', 'human', 'problem', 'effici', 'ever', 'with', 'greater', 'power', 'increas', 'data', 'give', 'human', 'though', 'come', 'increas', 'respons', '--', '--', 'easili', 'bigger', 'data', 'help', 'case', 'peopl', 'underinform', 'data', 'scienc', 'techniqu', \"n't\", 'awar', 'may', 'use', 'suitabl', 'practic', 'addit', 'data', 'sophist', 'techniqu', 'allow', 'poor', 'practition', 'get', 'other', 'troubl', 'faster', 'greater', 'magnitudes.', 'ultim', 'howev', 'i', 'think', 'increas', 'data', 'develop', 'comput', 'tool', 'methodolog', 'help', 'process', 'faster', 'better', 'one', 'biggest', 'benefit', 'human', 'seen', 'yet', '--', 'may', 'take', 'year', 'get', 'truli', 'excit', 'time', 'involv', 'data', 'scienc']\n"
       ]
      }
     ],
     "prompt_number": 192
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}